# AskMe - Offline Privacy-Centric Voice Assistant

[![GitHub Repository](https://img.shields.io/badge/GitHub-AskMe-blue?logo=github)](https://github.com/SunenaB3504/Askme)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://python.org)

## ğŸš€ Quick Links
- **ğŸ“ Repository**: [https://github.com/SunenaB3504/Askme](https://github.com/SunenaB3504/Askme)
- **ğŸ“– Documentation**: [docs/](docs/)
- **ğŸ¯ Quick Start for Nia**: [QUICK_START_NIA.md](QUICK_START_NIA.md)
- **ğŸ“‹ GitHub Guide**: [docs/github_guide.md](docs/github_guide.md)

## Project Overview

AskMe is a fully offline, privacy-centric voice assistant that leverages a custom-made Large Language Model (LLM) to provide intelligent conversational interaction without compromising user privacy. This system operates entirely on local hardware, ensuring that user data never leaves the device.

## Architecture Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Speech   â”‚â”€â”€â”€â–¶â”‚   ASR (Whisper) â”‚â”€â”€â”€â–¶â”‚  Text Input     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Speech Output  â”‚â—€â”€â”€â”€â”‚ TTS (Coqui TTS)â”‚â—€â”€â”€â”€â”‚ Custom LLM      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ (Fine-tuned)    â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                              â”‚   OpenWebUI     â”‚
                                              â”‚   Interface     â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Key Features

- **Complete Privacy**: All processing happens locally, no data sent to cloud
- **Multi-language Support**: English, Hindi, Tamil, and more
- **Real-time Processing**: Low-latency speech-to-text and response generation
- **Customizable**: Adaptable to specific domains and use cases
- **Open Source**: Built on open-source frameworks and models

## Quick Start

1. Set up the environment: `python setup.py install`
2. Download and configure models: `python scripts/setup_models.py`
3. Start the voice assistant: `python main.py`

## Documentation Structure

- [Installation Guide](docs/installation.md)
- [Model Training Guide](docs/model_training.md)
- [API Reference](docs/api_reference.md)
- [Performance Benchmarks](docs/performance.md)
- [Privacy & Security](docs/privacy.md)

## Project Structure

```
askme/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ llm/           # LLM fine-tuning and inference
â”‚   â”œâ”€â”€ asr/           # Speech recognition with Whisper
â”‚   â”œâ”€â”€ tts/           # Text-to-speech with Coqui TTS
â”‚   â”œâ”€â”€ ui/            # OpenWebUI integration
â”‚   â””â”€â”€ core/          # Core application logic
â”œâ”€â”€ models/            # Trained models and configurations
â”œâ”€â”€ data/              # Training datasets
â”œâ”€â”€ docs/              # Documentation
â”œâ”€â”€ tests/             # Unit and integration tests
â”œâ”€â”€ scripts/           # Setup and utility scripts
â””â”€â”€ configs/           # Configuration files
```

## License

MIT License - See [LICENSE](LICENSE) for details.
